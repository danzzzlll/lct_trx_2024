{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:57:04.342704Z",
     "iopub.status.busy": "2024-06-11T21:57:04.342091Z",
     "iopub.status.idle": "2024-06-11T21:57:04.352076Z",
     "shell.execute_reply": "2024-06-11T21:57:04.350436Z",
     "shell.execute_reply.started": "2024-06-11T21:57:04.342676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as ltb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "from lightautoml.tasks import Task\n",
    "import os\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TRAIN###\n",
    "train_trx = pd.read_parquet(\"../embeddings/train.parquet\")\n",
    "train_geo = pd.read_parquet(\"../embeddings/train_geo.parquet\")\n",
    "train_dial = pd.read_parquet(\"../embeddings/dialog_embs_m_train.parquet\")\n",
    "train_dial = train_dial.drop(columns=['event_time'])\n",
    "\n",
    "\n",
    "df_train = train_trx.merge(train_geo, on=['client_id', 'target_1', 'target_2', 'target_3', 'target_4'], how='outer')\n",
    "df_train = df_train.fillna(0)\n",
    "df_train = df_train.merge(train_dial, on=['client_id'], how='left')\n",
    "df_train = df_train.fillna(0)\n",
    "\n",
    "\n",
    "###TEST###\n",
    "test_trx = pd.read_parquet(\"../embeddings/not_only_trx.parquet\")\n",
    "test_geo = pd.read_parquet(\"../embeddings/test_geo.parquet\")\n",
    "test_dial = pd.read_parquet(\"../embeddings/dialog_embs_m_test.parquet\")\n",
    "test_dial = test_dial.drop(columns=['event_time'])\n",
    "test_dial['client_id'] = test_dial['client_id'].apply(lambda x: x.split('_')[0])\n",
    "test_dial = test_dial.groupby('client_id').agg('mean')\n",
    "\n",
    "\n",
    "df_test = test_trx.merge(test_geo, on='client_id')\n",
    "df_test = df_test.merge(test_dial, on='client_id', how='left')\n",
    "df_test = df_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000006265d27d1166ed67506682be7380007a5bead4362f0a9795f7d97fb08e3_month=1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[0].client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_production = TabularAutoML(\n",
    "                                    task=Task('binary', metric='auc', loss='logloss'), \n",
    "                                    reader_params={'n_jobs': 4, 'random_state': 42, 'advanced_roles': False},\n",
    "                                    debug=True,\n",
    "                                    general_params={\"use_algos\": [['denselight_tuned', 'autoint_tuned']]},\n",
    "                                    nn_params={\n",
    "                                        \"0\": {\n",
    "                                            \"bs\": 1024,\n",
    "                                            \"tuning_params\": {\n",
    "                                                \"max_tuning_iter\": 5,\n",
    "                                                \"max_tuning_time\": 100,\n",
    "                                                \"fit_on_holdout\": True\n",
    "                                                },\n",
    "                                            \"freeze_defaults\": True,\n",
    "                                            \"n_epochs\": 20,\n",
    "                                            'nn_params': {\n",
    "                                                'dnn_activation': 'relu',\n",
    "                                            }\n",
    "                                        },\n",
    "                                        '1': {\n",
    "                                            \"bs\": 1024,\n",
    "                                            \"tuning_params\": {\n",
    "                                                \"max_tuning_iter\": 5,\n",
    "                                                \"max_tuning_time\": 100,\n",
    "                                                \"fit_on_holdout\": True\n",
    "                                                },\n",
    "                                            'lr': 1e-3,\n",
    "                                            \"freeze_defaults\": True,\n",
    "                                            \"n_epochs\": 20\n",
    "                                        }\n",
    "                                    }\n",
    "\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train_embeddings):\n",
    "#         X_train = train_embeddings.drop(columns=self.drop_feat)\n",
    "    clfs = dict()\n",
    "    clf = automl_production\n",
    "    print(f'predict target:1')\n",
    "    clf.fit_predict(train_embeddings.drop(columns = ['target_2','target_3','target_4']), roles={'target': 'target_1'}, verbose=3)\n",
    "    cfls['target_1'] = clf\n",
    "\n",
    "    clf = automl_production\n",
    "    print(f'predict target:2')\n",
    "    clf.fit_predict(train_embeddings.drop(columns = ['target_1','target_3','target_4']), roles={'target': 'target_2'}, verbose=3)\n",
    "    cfls['target_2'] = clf\n",
    "\n",
    "    clf = automl_production\n",
    "    print(f'predict target:3')\n",
    "    clf.fit_predict(train_embeddings.drop(columns = ['target_1','target_2','target_4']), roles={'target': 'target_3'}, verbose=3)\n",
    "    cfls['target_3'] = clf\n",
    "\n",
    "    clf = automl_production\n",
    "    print(f'predict target:4')\n",
    "    clf.fit_predict(train_embeddings.drop(columns = ['target_2','target_3','target_1']), roles={'target': 'target_4'}, verbose=3)\n",
    "    cfls['target_4'] = clf\n",
    "\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict target:1\n",
      "[00:16:15] Stdout logging level is INFO3.\n",
      "[00:16:15] Task: binary\n",
      "\n",
      "[00:16:15] Start automl preset with listed constraints:\n",
      "[00:16:15] - time: 3600.00 seconds\n",
      "[00:16:15] - CPU: 4 cores\n",
      "[00:16:15] - memory: 16 GB\n",
      "\n",
      "[00:16:15] \u001b[1mTrain data shape: (8830335, 1282)\u001b[0m\n",
      "\n",
      "[00:17:47] Layer \u001b[1m1\u001b[0m train process start. Time left 3507.78 secs\n",
      "[00:33:49] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_TorchNN_denselight_tuned_0\u001b[0m ... Time budget is 100.00 secs\n"
     ]
    }
   ],
   "source": [
    "models = fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:57:05.448534Z",
     "iopub.status.busy": "2024-06-11T21:57:05.448047Z",
     "iopub.status.idle": "2024-06-11T21:57:05.473039Z",
     "shell.execute_reply": "2024-06-11T21:57:05.472107Z",
     "shell.execute_reply.started": "2024-06-11T21:57:05.448505Z"
    }
   },
   "outputs": [],
   "source": [
    "class Downstream:\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_path,\n",
    "        test_path,\n",
    "        params,\n",
    "        result_path,\n",
    "        col_id='client_id',\n",
    "        targets=(\n",
    "            'target_1',\n",
    "            'target_2',\n",
    "            'target_3',\n",
    "            'target_4'\n",
    "        )\n",
    "    ):\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.col_id = col_id\n",
    "        self.all_targets = targets\n",
    "        self.params = params\n",
    "        self.result_apth = result_path\n",
    "        self.model = automl_production = TabularAutoML(\n",
    "                                                        task=Task('binary', metric='auc', loss='logloss'), \n",
    "                                                        reader_params={'n_jobs': 4, 'cv': 2, 'random_state': 42, 'advanced_roles': False},\n",
    "                                                        debug=True,\n",
    "                                                        general_params={\"use_algos\": [['denselight', 'autoint']]},\n",
    "                                                        nn_params={\n",
    "                                                            \"0\": {\n",
    "                                                                \"bs\": 1024,\n",
    "                                                                \"freeze_defaults\": True,\n",
    "                                                                \"n_epochs\": 30,\n",
    "                                                                'dnn_params': {\n",
    "                                                                    'hidden_units': ((512, 0.2, True), (256, 0.2, True)),\n",
    "                                                                    'dnn_activation': 'relu',\n",
    "                                                                }\n",
    "                                                            },\n",
    "                                                            '1': {\n",
    "                                                                \"bs\": 1024,\n",
    "                                                                'lr': 1e-3,\n",
    "                                                                \"freeze_defaults\": True,\n",
    "                                                                \"n_epochs\": 30\n",
    "                                                            }\n",
    "                                                        }\n",
    "\n",
    "                                                    )\n",
    "\n",
    "        path = result_path\n",
    "        self.drop_feat = list(self.all_targets) + [self.col_id]\n",
    "\n",
    "    def fit(self):\n",
    "        train_embeddings = pd.read_parquet(self.train_path)\n",
    "        clfs = dict()\n",
    "        clf = self.model\n",
    "        clf.fit_predict(train_embeddings.drop(columns = ['target_2','target_3','target_4']), roles={'target': 'target_1'}, verbose=3)\n",
    "        cfls['target_1'] = clf\n",
    "        \n",
    "        clf = self.model\n",
    "        clf.fit_predict(train_embeddings.drop(columns = ['target_1','target_3','target_4']), roles={'target': 'target_2'}, verbose=3)\n",
    "        cfls['target_2'] = clf\n",
    "        \n",
    "        clf = self.model\n",
    "        clf.fit_predict(train_embeddings.drop(columns = ['target_1','target_2','target_4']), roles={'target': 'target_3'}, verbose=3)\n",
    "        cfls['target_3'] = clf\n",
    "        \n",
    "        clf = self.model\n",
    "        clf.fit_predict(train_embeddings.drop(columns = ['target_2','target_3','target_1']), roles={'target': 'target_4'}, verbose=3)\n",
    "        cfls['target_4'] = clf\n",
    "        \n",
    "        return clfs\n",
    "\n",
    "\n",
    "    def get_scores(self, clfs):\n",
    "        scores = pd.DataFrame([])\n",
    "        test_embeddings_curr = pd.read_parquet(self.test_path).drop_duplicates('client_id')\n",
    "        X_test = test_embeddings_curr.drop(columns=[self.col_id])\n",
    "        ids = test_embeddings_curr[self.col_id]\n",
    "        scores[self.col_id] = ids\n",
    "\n",
    "        for col_target in self.all_targets:\n",
    "            clf = clfs[col_target]\n",
    "            score = clf.predict_proba(X_test)[:, 1]\n",
    "            scores[col_target] = score\n",
    "            continue\n",
    "        return scores\n",
    "\n",
    "    def run(self):\n",
    "        clfs = self.fit()\n",
    "        scores = self.get_scores(clfs)\n",
    "        scores.to_csv(self.result_path)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = Downstream(\n",
    "    train_path=\"../embeddings/geo_trx_train.parquet\",\n",
    "    test_path=\"../embeddings/geo_not_only_trx.parquet\",\n",
    "    params=params,\n",
    "    result_path='/kaggle/working/submission.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T22:00:40.958589Z",
     "iopub.status.busy": "2024-06-11T22:00:40.957804Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = dw.run()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5180120,
     "sourceId": 8658613,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "py39tf",
   "language": "python",
   "name": "py39tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
