{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W interface.cpp:47] Warning: Loading nvfuser library failed with: Error in dlopen: libnvrtc.so.11.2: cannot open shared object file: No such file or directory (function LoadingNvfuserLibrary)\n",
      "/home/jovyan/.conda/envs/py39tf/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ptls.preprocessing import PandasDataPreprocessor\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from functools import partial\n",
    "from ptls.nn import TrxEncoder, RnnSeqEncoder, AggFeatureSeqEncoder\n",
    "from ptls.frames.coles import CoLESModule\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.frames.coles import ColesDataset\n",
    "from ptls.frames.coles.split_strategy import SampleSlices, NoSplit\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.data_load.datasets import inference_data_loader\n",
    "from ptls.nn import TrxEncoder, RnnSeqEncoder\n",
    "from ptls.data_load.iterable_processing.iterable_seq_len_limit import ISeqLenLimit\n",
    "from ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\n",
    "from ptls.data_load.iterable_processing.feature_filter import FeatureFilter\n",
    "from ptls.preprocessing import PandasDataPreprocessor\n",
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from ptls.data_load.iterable_processing_dataset import IterableProcessingDataset\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import lightgbm as ltb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_train = pd.read_parquet('../trx_train.parquet')\n",
    "trans_test = pd.read_parquet('../trx_test.parquet')\n",
    "\n",
    "trans_train = pd.concat([trans_train, trans_test])\n",
    "\n",
    "trans_train = trans_train[trans_train['event_time'].dt.year == 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_train['hour'] = trans_train['event_time'].dt.hour\n",
    "trans_train['weekday'] = trans_train['event_time'].dt.weekday\n",
    "\n",
    "trans_test['hour'] = trans_test['event_time'].dt.hour\n",
    "trans_test['weekday'] = trans_test['event_time'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target_b = pd.read_parquet(\"../test_target_b.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54min 2s, sys: 10min 14s, total: 1h 4min 16s\n",
      "Wall time: 1h 4min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "preprocessor = PandasDataPreprocessor(\n",
    "    col_id=\"client_id\",\n",
    "    col_event_time=\"event_time\",\n",
    "    event_time_transformation=\"dt_to_timestamp\",\n",
    "    cols_category=[\"event_type\",\n",
    "                   \"event_subtype\",\n",
    "                   \"currency\",\n",
    "                   \"src_type11\",\n",
    "                   \"src_type12\",\n",
    "                   \"dst_type11\",\n",
    "                   \"dst_type12\",\n",
    "                   \"src_type21\",\n",
    "                   \"src_type22\",\n",
    "                   \"src_type31\",\n",
    "                   \"src_type32\",\n",
    "                   'hour',\n",
    "                   'weekday'],\n",
    "    cols_identity=\"amount\",\n",
    "    return_records=True,\n",
    ")\n",
    "\n",
    "dataset_train = preprocessor.fit_transform(trans_train)\n",
    "dataset_test = preprocessor.transform(trans_test)\n",
    "\n",
    "dataset_train_df = pd.DataFrame(dataset_train)\n",
    "dataset_test_df = pd.DataFrame(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_train = [rec.get('client_id') for rec in dataset_train]\n",
    "\n",
    "target_train = pd.read_parquet(\"../train_target.parquet\")\n",
    "target_train = pd.concat([target_train, test_target_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_preprocessor = PandasDataPreprocessor(\n",
    "    col_id=\"client_id\",\n",
    "    col_event_time=\"mon\",\n",
    "    event_time_transformation=\"dt_to_timestamp\",\n",
    "    cols_identity=[\"target_1\", \"target_2\", \"target_3\", \"target_4\"],\n",
    "    return_records=False,\n",
    ")\n",
    "\n",
    "processed_target = target_preprocessor.fit_transform(target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отлаживаю этот блок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max_month(rec):\n",
    "    months_tensor = rec.get('event_time')\n",
    "    first_month = int(datetime.utcfromtimestamp(months_tensor[0].item()).strftime('%m'))\n",
    "    last_month = int(datetime.utcfromtimestamp(months_tensor[-1].item()).strftime('%m'))\n",
    "    year = int(datetime.utcfromtimestamp(months_tensor[0].item()).strftime('%Y'))\n",
    "    return first_month, last_month, year\n",
    "\n",
    "class GetSplit(IterableProcessingDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        start_month,\n",
    "        end_month,\n",
    "        year=2022,\n",
    "        col_id='client_id',\n",
    "        col_time='event_time'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.start_month = start_month\n",
    "        self.end_month = end_month\n",
    "        self._year = year\n",
    "        self._col_id = col_id\n",
    "        self._col_time = col_time\n",
    "\n",
    "    def __iter__(self):\n",
    "        \n",
    "        for rec in self._src:\n",
    "#             print(rec)\n",
    "            min_month, max_month, year = get_min_max_month(rec)\n",
    "            for month in range(self.start_month, self.end_month+1):\n",
    "                features = rec[0] if type(rec) is tuple else rec\n",
    "                features = features.copy()\n",
    "\n",
    "                if month == 12:\n",
    "                    month_event_time = datetime(self._year + 1, 1, 1).timestamp()\n",
    "                else:\n",
    "                    month_event_time = datetime(self._year, month + 1, 1).timestamp()\n",
    "\n",
    "                year_event_time = datetime(self._year, 1, 1).timestamp()\n",
    "\n",
    "                mask = features[self._col_time] < month_event_time\n",
    "\n",
    "                if month <= max_month:\n",
    "                    for key, tensor in features.items():\n",
    "                        if key.startswith('target'):\n",
    "                            target_index = month - 1\n",
    "                            if target_index < len(tensor):\n",
    "                                features[key] = tensor[target_index].tolist()\n",
    "                            else:\n",
    "                                break\n",
    "                        elif key != self._col_id:\n",
    "                            features[key] = tensor[mask]\n",
    "                else:\n",
    "                    # Stop iteration if there are no more targets\n",
    "                    break\n",
    "\n",
    "                features[self._col_id] += '_month=' + str(month)\n",
    "\n",
    "                yield features\n",
    "\n",
    "\n",
    "\n",
    "def collate_feature_dict_with_target(batch, col_id='client_id', targets=False):\n",
    "    batch_ids = []\n",
    "    target_cols = []\n",
    "    for sample in batch:\n",
    "        batch_ids.append(sample[col_id])\n",
    "        del sample[col_id]\n",
    "\n",
    "        if targets:\n",
    "            target_cols.append([sample[f'target_{i}'] for i in range(1, 5)])\n",
    "            del sample['target_1']\n",
    "            del sample['target_2']\n",
    "            del sample['target_3']\n",
    "            del sample['target_4']\n",
    "\n",
    "    padded_batch = collate_feature_dict(batch)\n",
    "    if targets:\n",
    "        return padded_batch, batch_ids, target_cols\n",
    "    return padded_batch, batch_ids\n",
    "\n",
    "\n",
    "class InferenceModuleMultimodal(pl.LightningModule):\n",
    "    def __init__(self, model, pandas_output=True, drop_seq_features=True, model_out_name='out'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.pandas_output = pandas_output\n",
    "        self.drop_seq_features = drop_seq_features\n",
    "        self.model_out_name = model_out_name\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_len = len(x)\n",
    "        if x_len == 3:\n",
    "            x, batch_ids, target_cols = x\n",
    "        else:\n",
    "            x, batch_ids = x\n",
    "\n",
    "        out = self.model(x)\n",
    "        if x_len == 3:\n",
    "            target_cols = torch.tensor(target_cols)\n",
    "            x_out = {\n",
    "                'client_id': batch_ids,\n",
    "                'target_1': target_cols[:, 0],\n",
    "                'target_2': target_cols[:, 1],\n",
    "                'target_3': target_cols[:, 2],\n",
    "                'target_4': target_cols[:, 3],\n",
    "                self.model_out_name: out\n",
    "            }\n",
    "        else:\n",
    "            x_out = {\n",
    "                'client_id': batch_ids,\n",
    "                self.model_out_name: out\n",
    "            }\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        if self.pandas_output:\n",
    "            return self.to_pandas(x_out)\n",
    "        return x_out\n",
    "\n",
    "    @staticmethod\n",
    "    def to_pandas(x):\n",
    "        expand_cols = []\n",
    "        scalar_features = {}\n",
    "\n",
    "        for k, v in x.items():\n",
    "            if type(v) is torch.Tensor:\n",
    "                v = v.cpu().numpy()\n",
    "\n",
    "            if type(v) is list or len(v.shape) == 1:\n",
    "                scalar_features[k] = v\n",
    "            elif len(v.shape) == 2:\n",
    "                expand_cols.append(k)\n",
    "            else:\n",
    "                scalar_features[k] = None\n",
    "\n",
    "        dataframes = [pd.DataFrame(scalar_features)]\n",
    "        for col in expand_cols:\n",
    "            v = x[col].cpu().numpy()\n",
    "            dataframes.append(pd.DataFrame(v, columns=[f'{col}_{i:04d}' for i in range(v.shape[1])]))\n",
    "\n",
    "        return pd.concat(dataframes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 34s, sys: 2min 38s, total: 24min 13s\n",
      "Wall time: 24min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train = MemoryMapDataset(\n",
    "    data=dataset_train_df.merge(processed_target.drop(\"event_time\", axis=1), on=\"client_id\", how=\"inner\").to_dict(\"records\"),\n",
    "    i_filters=[\n",
    "        ISeqLenLimit(max_seq_len=4096),\n",
    "        FeatureFilter(keep_feature_names=['client_id', 'target_1', 'target_2', 'target_3', 'target_4']),\n",
    "        GetSplit(start_month=1, end_month=12),\n",
    "        ToTorch(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test = MemoryMapDataset(\n",
    "    data=dataset_test_df.to_dict(\"records\"),\n",
    "    i_filters=[\n",
    "        ISeqLenLimit(max_seq_len=4096),\n",
    "        FeatureFilter(keep_feature_names=['client_id', 'target_1', 'target_2', 'target_3', 'target_4']),\n",
    "        ToTorch(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_train = [record.get('client_id') for record in train]\n",
    "clients_test = [record.get('client_id') for record in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target_1 = [record.get('target_1') for record in train]\n",
    "y_target_2 = [record.get('target_2') for record in train]\n",
    "y_target_3 = [record.get('target_3') for record in train]\n",
    "y_target_4 = [record.get('target_4') for record in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target_1 = [0 if isinstance(x, torch.Tensor) else x for x in y_target_1]\n",
    "y_target_2 = [0 if isinstance(x, torch.Tensor) else x for x in y_target_2]\n",
    "y_target_3 = [0 if isinstance(x, torch.Tensor) else x for x in y_target_3]\n",
    "y_target_4 = [0 if isinstance(x, torch.Tensor) else x for x in y_target_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'numeric_values': {\n",
    "        'amount': {'identity'},\n",
    "    },\n",
    "    'embeddings': {\n",
    "        # 'event_time': {'in': 40},\n",
    "        'event_type': {'in': 25},\n",
    "        'event_subtype': {'in': 25},\n",
    "        'src_type11': {'in': 30},\n",
    "        'src_type12': {'in': 30},\n",
    "        'dst_type11': {'in': 30},\n",
    "        'dst_type12': {'in': 30},\n",
    "        'src_type21': {'in': 30},\n",
    "        'src_type22': {'in': 30},\n",
    "        'src_type31': {'in': 30},\n",
    "        'src_type32': {'in': 30},\n",
    "        'hour': {'in': 12},\n",
    "        'weekday': {'in': 7},\n",
    "        \n",
    "    },\n",
    "}\n",
    "\n",
    "seq_encoder = AggFeatureSeqEncoder(**params)\n",
    "\n",
    "model = CoLESModule(\n",
    "    seq_encoder=seq_encoder,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=30, gamma=0.9),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    enable_progress_bar=True,\n",
    "    limit_val_batches=5000,\n",
    "    devices='auto',\n",
    "#     gpus=1,\n",
    "    gradient_clip_val=0.5,\n",
    "    # logger=pl.loggers.TensorBoardLogger(\n",
    "    #     save_dir='./logdir',\n",
    "    #     name='baseline_result'\n",
    "    # ),\n",
    "    callbacks=[\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval='step'),\n",
    "        pl.callbacks.ModelCheckpoint(every_n_train_steps=5000, save_top_k=-1),\n",
    "        pl.callbacks.EarlyStopping(monitor='valid/recall_top_k', mode=\"max\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "2024-06-16 17:27:43.211829: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-16 17:27:43.211888: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-16 17:27:43.211929: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-16 17:27:43.228033: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: |          | 487180/? [1:34:54<00:00, 85.55it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: |          | 14109/? [01:52<00:00, 125.44it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dl = inference_data_loader(train, num_workers=0, batch_size=16)\n",
    "train_embeds = torch.vstack(trainer.predict(model, train_dl))\n",
    "\n",
    "test_dl = inference_data_loader(test, num_workers=0, batch_size=16)\n",
    "test_embeds = torch.vstack(trainer.predict(model, test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_embeds.numpy() \n",
    "X_test = test_embeds.numpy()\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['client_id'] = clients_train\n",
    "\n",
    "X_train['target_1'] = y_target_1\n",
    "X_train['target_2'] = y_target_2\n",
    "X_train['target_3'] = y_target_3\n",
    "X_train['target_4'] = y_target_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 7694660, 1: 100220})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_target_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['client_id'] = clients_test\n",
    "\n",
    "not_only_trx = pd.DataFrame({\"client_id\": test_target_b[\"client_id\"].unique()}).merge(X_test, how=\"left\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>933</th>\n",
       "      <th>934</th>\n",
       "      <th>935</th>\n",
       "      <th>936</th>\n",
       "      <th>937</th>\n",
       "      <th>938</th>\n",
       "      <th>939</th>\n",
       "      <th>940</th>\n",
       "      <th>941</th>\n",
       "      <th>942</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2b7ff0c1c99cefe259ed83c5dfa0a403f2cbc88032b671...</td>\n",
       "      <td>598.0</td>\n",
       "      <td>2.423438e+08</td>\n",
       "      <td>4.052572e+05</td>\n",
       "      <td>1.358444e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0433d23e224b7a520656da6181efadb8d556bb293158c9...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.390542e+05</td>\n",
       "      <td>7.317570e+04</td>\n",
       "      <td>1.013245e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f2ce8b292e5f9f778f3e20db7608ac76dc8812113a2631...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4f807e8b163c653bcaeff9f925983568f4c3e6b1a1f231...</td>\n",
       "      <td>548.0</td>\n",
       "      <td>1.318522e+08</td>\n",
       "      <td>2.406063e+05</td>\n",
       "      <td>6.664959e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64369f6f8ae1b719332ee1bfb2b454e642b2053d2c9b8a...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.621085e+07</td>\n",
       "      <td>4.323912e+06</td>\n",
       "      <td>9.568857e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140483</th>\n",
       "      <td>d49a66825bb16ceb5b6a01126e1f2391b085dba8da44ee...</td>\n",
       "      <td>312.0</td>\n",
       "      <td>2.172017e+09</td>\n",
       "      <td>6.961592e+06</td>\n",
       "      <td>2.742429e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140484</th>\n",
       "      <td>f772af6720c0b591d49b97946c5e420c1c077affc0f7c7...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.492390e+06</td>\n",
       "      <td>8.291053e+04</td>\n",
       "      <td>2.045170e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140485</th>\n",
       "      <td>06b282335bc4853f888e1ab50a6ba23a8e420d42313959...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3.413228e+06</td>\n",
       "      <td>5.019454e+04</td>\n",
       "      <td>8.047743e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140486</th>\n",
       "      <td>90d423a25d7cdaf674f7d78bc37d88830443ff17717e02...</td>\n",
       "      <td>745.0</td>\n",
       "      <td>5.033785e+07</td>\n",
       "      <td>6.756759e+04</td>\n",
       "      <td>1.699165e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140487</th>\n",
       "      <td>f63e55b226d3732b8b4927be8a2cdc7fb88ff2bb0561e2...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.431696e+05</td>\n",
       "      <td>3.215848e+04</td>\n",
       "      <td>3.115130e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140488 rows × 944 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                client_id      0  \\\n",
       "0       2b7ff0c1c99cefe259ed83c5dfa0a403f2cbc88032b671...  598.0   \n",
       "1       0433d23e224b7a520656da6181efadb8d556bb293158c9...    6.0   \n",
       "2       f2ce8b292e5f9f778f3e20db7608ac76dc8812113a2631...    0.0   \n",
       "3       4f807e8b163c653bcaeff9f925983568f4c3e6b1a1f231...  548.0   \n",
       "4       64369f6f8ae1b719332ee1bfb2b454e642b2053d2c9b8a...   13.0   \n",
       "...                                                   ...    ...   \n",
       "140483  d49a66825bb16ceb5b6a01126e1f2391b085dba8da44ee...  312.0   \n",
       "140484  f772af6720c0b591d49b97946c5e420c1c077affc0f7c7...   18.0   \n",
       "140485  06b282335bc4853f888e1ab50a6ba23a8e420d42313959...   68.0   \n",
       "140486  90d423a25d7cdaf674f7d78bc37d88830443ff17717e02...  745.0   \n",
       "140487  f63e55b226d3732b8b4927be8a2cdc7fb88ff2bb0561e2...   20.0   \n",
       "\n",
       "                   1             2             3    4      5      6     7  \\\n",
       "0       2.423438e+08  4.052572e+05  1.358444e+06  0.0  264.0  242.0   0.0   \n",
       "1       4.390542e+05  7.317570e+04  1.013245e+05  0.0    4.0    0.0   1.0   \n",
       "2       0.000000e+00  0.000000e+00  0.000000e+00  0.0    0.0    0.0   0.0   \n",
       "3       1.318522e+08  2.406063e+05  6.664959e+05  0.0  482.0   22.0   2.0   \n",
       "4       5.621085e+07  4.323912e+06  9.568857e+06  0.0    7.0    0.0   0.0   \n",
       "...              ...           ...           ...  ...    ...    ...   ...   \n",
       "140483  2.172017e+09  6.961592e+06  2.742429e+07  0.0   30.0   13.0  76.0   \n",
       "140484  1.492390e+06  8.291053e+04  2.045170e+05  0.0   13.0    0.0   0.0   \n",
       "140485  3.413228e+06  5.019454e+04  8.047743e+04  0.0   39.0    0.0  18.0   \n",
       "140486  5.033785e+07  6.756759e+04  1.699165e+05  0.0   47.0  113.0  58.0   \n",
       "140487  6.431696e+05  3.215848e+04  3.115130e+04  0.0    9.0   11.0   0.0   \n",
       "\n",
       "            8  ...  933  934  935   936  937  938  939  940   941  942  \n",
       "0        14.0  ...  2.0  2.0  4.0   7.0  1.0  1.0  1.0  1.0  11.0  6.0  \n",
       "1         1.0  ...  1.0  1.0  3.0   3.0  1.0  1.0  1.0  1.0   5.0  4.0  \n",
       "2         0.0  ...  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  0.0  \n",
       "3         0.0  ...  1.0  1.0  6.0   9.0  1.0  1.0  1.0  1.0  11.0  6.0  \n",
       "4         0.0  ...  3.0  3.0  3.0   4.0  1.0  1.0  1.0  1.0   7.0  5.0  \n",
       "...       ...  ...  ...  ...  ...   ...  ...  ...  ...  ...   ...  ...  \n",
       "140483    0.0  ...  5.0  3.0  8.0   9.0  1.0  1.0  1.0  1.0  11.0  6.0  \n",
       "140484    0.0  ...  3.0  3.0  5.0   5.0  1.0  1.0  1.0  1.0   5.0  6.0  \n",
       "140485    3.0  ...  4.0  6.0  7.0  11.0  1.0  1.0  1.0  1.0  10.0  6.0  \n",
       "140486  322.0  ...  5.0  5.0  7.0   9.0  1.0  1.0  1.0  1.0  11.0  6.0  \n",
       "140487    0.0  ...  1.0  1.0  2.0   2.0  1.0  1.0  1.0  1.0   7.0  6.0  \n",
       "\n",
       "[140488 rows x 944 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_only_trx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns = X_train.columns.map(lambda x: str(x) if isinstance(x, int) else x)\n",
    "X_train.to_parquet(\"X_train_trx.parquet\", index=False, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_only_trx.columns = not_only_trx.columns.map(lambda x: str(x) if isinstance(x, int) else x)\n",
    "not_only_trx.to_parquet(\"X_test_trx.parquet\", index=False, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39tf",
   "language": "python",
   "name": "py39tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
